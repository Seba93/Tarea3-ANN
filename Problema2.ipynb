{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entrenamiento de RNNs en una Serie de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Imports necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seba/.virtualenvs/tareas-ml/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce 820M (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import cross_validation\n",
    "import math\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Creación de conjuntos de entrenamiento y prueba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se crean los conjuntos de entrenamiento y de prueba por medio de la función *create_sets*. Esta función también se encarga de escalar los datos de cada conjunto, de tal manera que cada cada atributo de cada ejemplo tendrá un valor entre 0 y 1. El dataset original está compuesto por un total de 144 registros, de los cuales 96 estarán destinados a conformar el conjunto de entrenamiento, mientras que los 48 restantes formarán parte del conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para la creación de conjuntos de entrenamiento y prueba\n",
    "def create_sets(file_name):\n",
    "    # Se lee archivo que contiene todos los datos\n",
    "    dataframe = pandas.read_csv(file_name, sep=',', usecols=[1], engine='python', skipfooter=3)\n",
    "    # Se utiliza precisión de 32 bits para atributos numéricos\n",
    "    dataframe[:] = dataframe[:].astype('float32')\n",
    "    # Se crean conjuntos de entrenamiento y de prueba\n",
    "    df_train, df_test = dataframe[0:96].values, dataframe[96:].values\n",
    "    # Se escalan los datos de cada conjunto\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df_train)\n",
    "    stream_train_scaled = scaler.transform(df_train)\n",
    "    stream_test_scaled = scaler.transform(df_test)\n",
    "    return scaler, list(stream_train_scaled), list(stream_test_scaled)\n",
    "\n",
    "# Se crean conjuntos a partir de archivo .csv\n",
    "scaler, train_set, test_set = create_sets('international-airline-passengers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Separación de atributos predictores y atributo a predecir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya creados los conjuntos de entrenamiento y de prueba, se procede a construir, para cada caso, la matriz X y el vector Y.\n",
    "\n",
    "Considerar, por ejemplo, un lag = 3. En tal caso, la matriz X contendrá, para cada registro, la cantidad de pasajeros en los tiempos x(t-2), x(t-1) y x(t), o en otras palabras, los atributos predictores. Por otro lado, el vector Y almacenará en la casilla correspondiente la cantidad de pasajeros en el tiempo x(t+1), es decir, el atributo a predecir. El procedimiento descrito será llevado a cabo por medio de la función *create_dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función encargada de separar valores predictores y valores a predecir\n",
    "def create_dataset(sequence, lag):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(lag, len(sequence)):\n",
    "        # Se crea matriz X\n",
    "        dataX.append(sequence[i - lag : i])\n",
    "        # Se crea vector Y\n",
    "        dataY.append(sequence[i])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se crea la matriz X y el vector Y en base a los conjuntos de entrenamiento y de prueba. Se utilizará lag = 3, en primera instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inicialmente, se usará lag = 3\n",
    "lag = 3\n",
    "# Se crean matrices X y vectores Y en base a conjuntos de entrenamiento y prueba\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar adecuadamente con las matrices X, es necesario redimensionarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, cada matriz X posee dimensiones (número de ejemplos, time step, número de atributos predictores) tanto para el caso de entrenamiento como para el caso de pruebas. Notar que, por ahora, se está trabajando con un time step = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Entrenamiento de red LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las matrices creadas en la sección anterior, se entrena y posteriormente se evalúa una red LSTM. Recordar que se está utilizando un lag de 3. Además, para este caso en particular, se trabajará con cuatro bloques LSTM, función de activación tanh y función de activación sigmoide para el paso recurrente. Para medir la pérdida en el entrenamiento, se usará Mean Squared Error (MSE), mientras que como método de optimización, se usará Adam. Se llevarán a cabo 100 epochs, con batches de tamaño 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s - loss: 0.1004     \n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 1s - loss: 0.0459     \n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 1s - loss: 0.0267     \n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 1s - loss: 0.0210     \n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 1s - loss: 0.0178     \n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 1s - loss: 0.0154     \n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 1s - loss: 0.0134     \n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 1s - loss: 0.0117     \n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 1s - loss: 0.0104     \n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 1s - loss: 0.0096     \n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 1s - loss: 0.0090     \n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 1s - loss: 0.0085     \n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 1s - loss: 0.0082     \n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 1s - loss: 0.0079     \n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 1s - loss: 0.0077     \n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 1s - loss: 0.0076     \n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 1s - loss: 0.0074     \n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 1s - loss: 0.0075     \n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 1s - loss: 0.0073     \n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 1s - loss: 0.0072     \n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 1s - loss: 0.0073     \n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 1s - loss: 0.0073     \n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 1s - loss: 0.0071     \n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 1s - loss: 0.0071     \n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 1s - loss: 0.0069     \n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 1s - loss: 0.0069     \n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 1s - loss: 0.0069     \n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 1s - loss: 0.0069     \n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 1s - loss: 0.0068     \n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 1s - loss: 0.0070     \n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 1s - loss: 0.0066     \n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 1s - loss: 0.0066     \n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 1s - loss: 0.0067     \n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 1s - loss: 0.0066     \n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 1s - loss: 0.0064     \n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 1s - loss: 0.0063     \n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 1s - loss: 0.0064     \n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 1s - loss: 0.0062     \n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 1s - loss: 0.0064     \n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 1s - loss: 0.0064     \n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 1s - loss: 0.0062     \n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 1s - loss: 0.0061        - ETA\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 1s - loss: 0.0061     \n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 1s - loss: 0.0061     \n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 1s - loss: 0.0061     \n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 1s - loss: 0.0060     \n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 1s - loss: 0.0060     \n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 1s - loss: 0.0060     \n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 1s - loss: 0.0060        - ETA:\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 1s - loss: 0.0058     \n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 1s - loss: 0.0058     \n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 1s - loss: 0.0058     \n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 1s - loss: 0.0061     \n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 1s - loss: 0.0059     \n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 1s - loss: 0.0058     \n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 1s - loss: 0.0054     \n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 1s - loss: 0.0054     \n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 1s - loss: 0.0054     \n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 1s - loss: 0.0053     \n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 1s - loss: 0.0057     \n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 1s - loss: 0.0053     \n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 1s - loss: 0.0056     \n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 1s - loss: 0.0054     \n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 1s - loss: 0.0054     \n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 1s - loss: 0.0055     \n"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "# Se define modelo\n",
    "model = Sequential()\n",
    "# Se define capa LSTM\n",
    "model.add(LSTM(4, input_shape=(None, lag), activation='tanh', recurrent_activation='sigmoid'))\n",
    "# Se define capa densa\n",
    "model.add(Dense(1))\n",
    "# Se definen parámetros de entrenamiento\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# Se entrena modelo\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1)\n",
    "tf = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Determinación de error de entrenamiento y de prueba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del modelo entrenado en la sección 2.3, se realizan predicciones tanto en el modelo de entrenamiento como en el de prueba. Junto con esto, se denormalizan los valores reales y los valores predichos para posteriormente determinar el error de predicción en la escala original en que se encontraban los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se predicen valores en conjunto de entrenamiento\n",
    "trainPredict = model.predict(trainX)\n",
    "# Se predicen valores en conjunto de prueba\n",
    "testPredict = model.predict(testX)\n",
    "# Datos reales y predichos de entrenamiento son denormalizados\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "# Datos reales y predichos de prueba son denormalizados\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, en base a los valores denormalizados, se procede a determinar el error de predicción tanto de entrenamiento como de prueba. En cada caso, lo que se computará será el RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 151.644290924 [s]\n",
      "Error de entrenamiento: 23.1198275993 RMSE\n",
      "Error de prueba: 69.9123963547 RMSE\n"
     ]
    }
   ],
   "source": [
    "# Se determina error de entrenamiento\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "# Se determina error de prueba\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "# Se determina tiempo de entrenamiento\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se observa que el tiempo requerido para entrenar el modelo es de aproximádamente 151,64 [s]. Por otra parte, el error de entrenamiento es de 23,12 RMSE, mientras que el error de prueba es de 69,91 RMSE, aumentando considerablemente con respecto al error de entrenamiento, en base a lo cual se puede inferior que el modelo está sobreajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Comparación de predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se procede a graficar, para cada conjunto de datos, la evolución de la serie en función del tiempo. En cada gráfico, se compara la evolución de la serie original en contraste con la serie predicha. Notar que como se está trabajando con lag = 3, las curvas asociadas a las series predichas comienzan en el tiempo lag + 1 = 4.\n",
    "\n",
    "Primero, se grafican las series obtenidas para el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI7jOFH5f1phDA4laZ8rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcde992be90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_set)), scaler.inverse_transform(train_set), 'b')\n",
    "plt.plot(range(len(train_set))[lag:], list(trainPredict), 'r')\n",
    "plt.title('Valor de la serie vs Tiempo (Caso entrenamiento)')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor de la serie')\n",
    "plt.legend(['Serie original', 'Serie predicha'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico anterior muestra como existen escasas diferencias entre una curva y otra, lo que es consistente con el \"aceptable\" error de entrenamiento percibido.\n",
    "\n",
    "De forma, análoga se construye el gráfico descrito para el caso del conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZvrS52YEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcde9827790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(test_set)), scaler.inverse_transform(test_set), 'b')\n",
    "plt.plot(range(len(test_set))[lag:], list(testPredict), 'r')\n",
    "plt.title('Valor de la serie vs Tiempo (Caso prueba)')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor de la serie')\n",
    "plt.legend(['Serie original', 'Serie predicha'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible ver como las curvas se distancian cada vez más entre si a medida que el tiempo avanza, hecho que puede tener su origen en la propagación del error. Además, se observan anomalías, como la presencia de máximos locales en la serie original que se corresponden con mínimos en la serie predicha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Determinación de bloques LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de mejorar los resultados obtenidos anteriormente, se requiere conocer cual es la cantidad de bloques LSTM que permitirá disminuir el error y/o el tiempo de entrenamiento. Tal cantidad será determinada por medio K-fold Cross Validation, con K = 5, por lo que, para cada tamaño de bloque posible, se informa el tiempo y el error **promedio**. Se experimentará con bloques de tamaño 4, 6, 8, 10 y 12. El lag continuará siendo 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de bloques: 4\n",
      "Tiempo de entrenamiento promedio: 94.1440439224 [s]\n",
      "Error promedio: 24.9563698551\n",
      "\n",
      "Numero de bloques: 6\n",
      "Tiempo de entrenamiento promedio: 102.017626047 [s]\n",
      "Error promedio: 23.996260032\n",
      "\n",
      "Numero de bloques: 8\n",
      "Tiempo de entrenamiento promedio: 103.57533884 [s]\n",
      "Error promedio: 22.9543083832\n",
      "\n",
      "Numero de bloques: 10\n",
      "Tiempo de entrenamiento promedio: 31.4311478138 [s]\n",
      "Error promedio: 21.6224803015\n",
      "\n",
      "Numero de bloques: 12\n",
      "Tiempo de entrenamiento promedio: 34.2996850014 [s]\n",
      "Error promedio: 22.3339488603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# Se definen los folds a utilizar\n",
    "kfold = cross_validation.KFold(trainX.shape[0], 5)\n",
    "\n",
    "# Se determina el tiempo y error de entrenamiento para cada cantidad de bloques posible\n",
    "for nb in range(4, 13, 2):\n",
    "    cv_errors = []\n",
    "    times = []\n",
    "    print 'Numero de bloques:', nb\n",
    "    for i, (train, val) in enumerate(kfold):\n",
    "        model = None\n",
    "        ti = time.time()\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(nb, input_shape=(None, lag), activation='tanh', recurrent_activation='sigmoid'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX[train], trainY[train], epochs=100, batch_size=1, verbose=0)\n",
    "        tf = time.time()\n",
    "        times.append(tf - ti)\n",
    "        trainPredict_val = model.predict(trainX[val])\n",
    "        trainPredict_val = scaler.inverse_transform(trainPredict_val)\n",
    "        trainY_val = scaler.inverse_transform(trainY[val])\n",
    "        error = math.sqrt(mean_squared_error(trainY_val, trainPredict_val))\n",
    "        cv_errors.append(error)\n",
    "    mean_time = np.mean(times)\n",
    "    mse_cv = np.mean(cv_errors)\n",
    "    print 'Tiempo de entrenamiento promedio:', tf - ti, '[s]'\n",
    "    print 'Error promedio:', mse_cv\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que no existe gran diferencia entre los errores obtenidos para cada cantidad de bloques posible. El error más bajo es conseguido con 10 bloques (21,62 RMSE), cantidad con la que también se obtiene el tiempo de entrenamiento más bajo, por lo que para los experimentos a realizar en las secciones posteriores se utilizarán siempre 10 bloques.\n",
    "\n",
    "Como observación, es interesante ver que no existe una relación, ya sea directa o indirecta, entre el número de bloques utilizados y el error de entrenamiento, así como tampoco entre el número de bloques y el tiempo de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7 Variación de lag**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se evaluará el impacto de modificar el lag en términos del tiempo de entrenamiento y el error de prueba. En otras palabras, los valores futuros serán determinados a partir de una cantidad variable de valores pasados. Se trabará con lags 1, 2, 3 y 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag: 1\n",
      "Tiempo de entrenamiento: 38.9600961208 [s]\n",
      "Error de entrenamiento: 23.0858198495 RMSE\n",
      "Error de prueba: 50.6355843488 RMSE\n",
      "\n",
      "Lag: 2\n",
      "Tiempo de entrenamiento: 38.2354969978 [s]\n",
      "Error de entrenamiento: 21.2587592529 RMSE\n",
      "Error de prueba: 56.3153569961 RMSE\n",
      "\n",
      "Lag: 3\n",
      "Tiempo de entrenamiento: 37.7705950737 [s]\n",
      "Error de entrenamiento: 21.8260095946 RMSE\n",
      "Error de prueba: 59.410653358 RMSE\n",
      "\n",
      "Lag: 4\n",
      "Tiempo de entrenamiento: 37.3015160561 [s]\n",
      "Error de entrenamiento: 21.9020619436 RMSE\n",
      "Error de prueba: 63.4056897616 RMSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lag in range(1, 5):\n",
    "    trainX, trainY = create_dataset(train_set, lag)\n",
    "    testX, testY = create_dataset(test_set, lag)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    ti = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(None, lag), activation='tanh', recurrent_activation='sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=0)\n",
    "    tf = time.time()\n",
    "    \n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "    \n",
    "    print 'Lag:', lag\n",
    "    print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "    print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "    print 'Error de prueba:', testScore, 'RMSE\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que el tiempo de entrenamiento aumenta con la variación del lag, si se compara con el caso de lag = 3 y 10 bloques LSTM. Además, se observa que el error de prueba tiende a aumentar a medida que también lo hace el lag. Esto es, el error de prueba más bajo se consigue con lag = 1, siendo este de un 48,55 RMSE. Para dicho lag, el tiempo de entrenamiento fue de 34,23 [s].\n",
    "\n",
    "Notar, por otro lado, que independiente del lag utilizado, el error de prueba siempre resultó ser más bajo respecto al caso original, en que se utilizó lag = 3 y número de bloques = 4, recordando que en la presente sección siempre se usaron 10 bloques, reafirmando la conveniencia de utilizar la recien mencionada cantidad de bloques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8 Comparación con RNN simple y GRU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea comparar el rendimiento de las redes LSTM implementadas hasta ahora con el de una RNN simple y el de una Gated Recurrent Unit (GRU). Se considerará lag = 3 y 10 bloques.\n",
    "\n",
    "Primero se determina el rendimiento de la GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 30.681374073 [s]\n",
      "Error de entrenamiento: 22.9943455919 RMSE\n",
      "Error de prueba: 73.8763318143 RMSE\n"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(GRU(10, input_shape=(None, lag), recurrent_initializer='orthogonal', activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=0)\n",
    "tf = time.time()\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "De forma análoga, se estudia el rendimiento de la RNN simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 19.7333681583 [s]\n",
      "Error de entrenamiento: 24.794535324 RMSE\n",
      "Error de prueba: 52.5739156004 RMSE\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(10, input_shape=(None, lag), recurrent_initializer='orthogonal', activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=0)\n",
    "tf = time.time()\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.9 Entrenamiento de red LSTM con timestep = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95/95 [==============================] - 0s - loss: 0.1204     \n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s - loss: 0.0548     \n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s - loss: 0.0334     \n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s - loss: 0.0280     \n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s - loss: 0.0248     \n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s - loss: 0.0217     \n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s - loss: 0.0188     \n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s - loss: 0.0163     \n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s - loss: 0.0136     \n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s - loss: 0.0116     \n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s - loss: 0.0101     \n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s - loss: 0.0088     \n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s - loss: 0.0076     \n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s - loss: 0.0072     \n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s - loss: 0.0065     \n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s - loss: 0.0063     \n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 23/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 24/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 25/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 26/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 27/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 28/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 29/100\n",
      "95/95 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 30/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 31/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 32/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 33/100\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 34/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 35/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 36/100\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 37/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 38/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 39/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 40/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 41/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 42/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 43/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 44/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 45/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 46/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 47/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 48/100\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 49/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 50/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 51/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 52/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 53/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 54/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 55/100\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 56/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 57/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 58/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 59/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 60/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 61/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 62/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 63/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 64/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 65/100\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 66/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 67/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 68/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 69/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 70/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 71/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 72/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 73/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 74/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 75/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 76/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 77/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 78/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 79/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 80/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 81/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 82/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 83/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 84/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 85/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 86/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 87/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 88/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 89/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 90/100\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 91/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 92/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 93/100\n",
      "95/95 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 94/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 95/100\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 96/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 97/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 98/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 99/100\n",
      "95/95 [==============================] - 0s - loss: 0.0056     \n",
      "Epoch 100/100\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n"
     ]
    }
   ],
   "source": [
    "lag = 1\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(None, lag), activation='tanh', recurrent_activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1)\n",
    "tf = time.time()\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 43.8619568348 [s]\n",
      "Error de entrenamiento: 22.9169657 RMSE\n",
      "Error de prueba: 49.1911529774 RMSE\n"
     ]
    }
   ],
   "source": [
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.10 Entrenamiento de red LSTM con memoria entre batches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.10.1 Batch size = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0108     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0142     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0111     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0105     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0101     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0099     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0097     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0096     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0094     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0093     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0092     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0090     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0089     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0088     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0087     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0085     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0084     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0083     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0082     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0081     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0080     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0078     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0077     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0076     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0075     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0074     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0073     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0072     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0071     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0070     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0069     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0068     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0067     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0066     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0065     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0064     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0063     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0062     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0061     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0058     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0056     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0054     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0053     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0052     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0052     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0049     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0049     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0045     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0045     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0045     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0045     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n"
     ]
    }
   ],
   "source": [
    "lag = 1\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "batch_size = 1\n",
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, lag, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, shuffle=False)\n",
    "    model.reset_states()\n",
    "tf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 39.4478318691 [s]\n",
      "Error de entrenamiento: 20.7738267992 RMSE\n",
      "Error de prueba: 44.4142693212 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.10.2 Batch size = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.1576     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0431      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0328     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0323     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0265     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0227     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0192     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0163     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0141      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0125      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0115      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0110      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0108      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0107      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0106      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0106      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0105      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0104      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0104      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0104      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0104      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.0080  - 0s - loss: 0.0104     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0104      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0103      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0102      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0102      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0102      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.0083  - 0s - loss: 0.0102     \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0102      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0102      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0101      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0100      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0099      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0098      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0097      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0096      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0095      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0094      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0094      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0094      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0094      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0094      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0093      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0093      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0093      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0093      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0093      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0092      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0092      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0092      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0092      \n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s - loss: 0.0092      \n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "batch_size = 3\n",
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, lag, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, shuffle=False)\n",
    "    model.reset_states()\n",
    "tf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 24.7862110138 [s]\n",
      "Error de entrenamiento: 29.2695560127 RMSE\n",
      "Error de prueba: 72.1762234158 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.11 Entrenamiento de LSTM apilada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0126     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0251     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0174     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0142     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0143     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0142     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0153     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0146     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0151     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0154     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0153     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0154     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0152     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0151     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0149     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0146     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0143     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0138     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0132     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0123     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0111     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0095     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0079     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0070     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0063     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0060     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0057     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0055     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0053     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0049     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0048     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0047     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0046     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0045     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0044     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0042     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0041     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0040     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0040     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0040     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0038     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0037     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n",
      "Epoch 1/1\n",
      "95/95 [==============================] - 0s - loss: 0.0036     \n"
     ]
    }
   ],
   "source": [
    "lag = 1\n",
    "trainX, trainY = create_dataset(train_set, lag)\n",
    "testX, testY = create_dataset(test_set, lag)\n",
    "   \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "ti = time.time()\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, lag, 1), stateful=True, return_sequences=True))\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, lag, 1), stateful=True, return_sequences=True))\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, lag, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, shuffle=False)\n",
    "    model.reset_states()\n",
    "tf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 103.771305084 [s]\n",
      "Error de entrenamiento: 17.4679926672 RMSE\n",
      "Error de prueba: 87.0944367797 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "\n",
    "print 'Tiempo de entrenamiento:', tf - ti, '[s]'\n",
    "print 'Error de entrenamiento:', trainScore, 'RMSE'\n",
    "print 'Error de prueba:', testScore, 'RMSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
